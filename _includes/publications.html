<h2 style="padding-top: 30px;"><b>publications</b></h2>

<table style="padding-top: 10px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
  <tr>
    <td style="padding-right: 20px; width:25%;vertical-align:middle">
      <img src="assets/img/epson.jpg" alt="clean-usnob" width="160" height="140">
    </td>
    <td width="75%" valign="middle">
      <p1>
      <strong>SKP: Semantic 3D Keypoint Detection for Category-Level Robotic Manipulation</strong>
      <br> Zhongzhen Luo , Wenjie Xue, <strong> Julia Chae </strong>, Guoyi Fu
      <br><em><a href="https://www.ieee-ras.org/publications/ra-l">IEEE Robotics and Automation Letters</a></em>, April 2022
      <br> <a href="https://ieeexplore.ieee.org/document/9730091/">Journal Paper</a>
      <br> <br> SKP is a multi-task perception module which jointly optimizes keypoint and part-segmentation learning in order to improve generalizability of category-level objects for robotic grasping. This model demonstrates accurate performance in real data, while being trained purely in the synthetic domain. </p1>
    </td>
  </tr>
</tbody></table>

<table style="padding-top: 20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
  <tr>
    <td style="padding-right: 20px; width:25%;vertical-align:middle">
      <img src="assets/img/CaDDN.gif" alt="clean-usnob" width="160" height="140">
    </td>
    <td width="75%" valign="middle">
      <p1>
      <strong>Categorical Depth Distribution Network for Monocular 3D Object Detection</strong>
      <br> Cody Reading, Ali Harakeh, <strong> Julia Chae </strong>, Steven L. Waslander
      <br>[Oral Presentation]. <em><a href="http://cvpr2021.thecvf.com/">Conference on Computer Vision and Pattern Recognition</a></em>, 2021
      <br> <a href="https://trailab.github.io/CaDDN/">Project Page</a> / <a href="https://arxiv.org/pdf/2103.01100.pdf">Paper</a> / <a href="https://github.com/TRAILab/CaDDN">Code</a> / <a href="https://www.youtube.com/watch?v=E3NoO_c6tPg&t=5s&ab_channel=trailab">Talk</a>
      <br> <br> CaDDN is an approach for joint depth estimation and object detection that uses a predicted categorical depth distribution for each pixel to project contextual feature information in 3D space. CaDDN ranked 1st amongst published monocular methods on KITTI and Waymo 3D object detection datasets at publication.</p1>
    </td>
  </tr>
</tbody></table>

<h2 style="padding-top: 30px;"><b>theses</b></h2>

<table style="padding-top: 10px; width:100%;border:0px;border-spacing:0px;border-collapse:separate;"><tbody>  
  <tr>
    <td style="padding-right: 20px; width:25%;vertical-align:middle">
      <img src="assets/img/selfsup.jpg" alt="clean-usnob" width="160" height="140">
    </td>
    <td width="75%" valign="middle">
      <p1>
      <strong>Self-supervised Dense Representation Learning </strong>
      <strong> Julia Chae </strong>
      <br> [BASc Thesis] @ <strong><a href="https://engsci.utoronto.ca/program/thesis/">U of T Eng Sci</a></strong>, supervised by <strong><a href="https://www.trailab.utias.utoronto.ca/">Sanja Fidler</a></strong> 
      <br> <br> Thesis on the exploration of inter-image relationships for contrastive learning to investigate how context between images can be used to improve part-based dense representation learning. </p1>
      <br> <br>
    </td>
  </tr>
</tbody></table>